{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3: Embedding Models for Retrieval\n",
    "\n",
    "**Objective**: Understand the role of embeddings in representing document chunks for retrieval.\n",
    "\n",
    "**Topics**:\n",
    "- Overview of embedding models: LLM-Embedder, BAAI/bge, etc.\n",
    "- Selecting the right embedding model\n",
    "- Integrating embeddings into the retrieval pipeline\n",
    "\n",
    "**Practical Task**: Implement and test embedding models on the chunked documents.\n",
    "\n",
    "**Resources**:\n",
    "- Choosing and embedding model\n",
    "- How to select an embedding model\n",
    "- [Mastering RAG: How to Select an Embedding Model](https://www.rungalileo.io/blog/mastering-rag-how-to-select-an-embedding-model#:~:text=Embeddings%20encode%20the%20semantics%20of,efficient%20and%20user%20friendly%20experience.)\n",
    "- [Vector Embeddings in RAG Applications](https://wandb.ai/mostafaibrahim17/ml-articles/reports/Vector-Embeddings-in-RAG-Applications--Vmlldzo3OTk1NDA5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = (\n",
    "    \"../data/Regulaciones cacao y chocolate 2003.pdf\"\n",
    ")\n",
    "loader = PyPDFLoader(file_path)\n",
    "doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFMinerLoader\n",
    "\n",
    "file_path = \"../data/Regulaciones cacao y chocolate 2003.pdf\"\n",
    "loader = PDFMinerLoader(file_path)\n",
    "doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Status:  This is the original version (as it was originally made).\\nSTATUTORY INSTRUMENTS\\n2003 No. 1659\\nFOOD, ENGLAND\\nThe Cocoa and Chocolate Products (England) Regulations 2003\\nMade        -      -       -      - 25th June 2003\\nLaid before Parliament 3rd July 2003\\nComing into force       -      - 3rd August 2003\\nThe Secretary of State, in exercise of the powers conferred by sections 16(1)(e), 17(1), 26(1) and (3)\\nand 48(1) of the Food Safety Act 1990 (1) and now vested in him (2) and of all other powers enabling\\nhim in that behalf, having had regard in accordance with section 48(4A) of that Act to relevant\\nadvice given by the Food Standards Agency, and after consultation both as required by Article 9\\nof Regulation (EC) No. 178/2002  of the European Parliament and of the Council laying down the\\ngeneral principles and requirements of food law, establishing the European Food Safety Authority\\nand laying down procedures in matters of food safety (3) and in accordance with section 48(4) and\\n(4B) of that Act, hereby makes the following Regulations:\\nTitle, commencement and application\\n1.These Regulations may be cited as the Cocoa and Chocolate Products (England) Regulations\\n2003, shall come into force on 3rd August 2003 and shall apply to England only.\\nInterpretation\\n2.—(1)  In these Regulations—\\n“the Act” means the Food Safety Act 1990;\\n(1)1990 c. 16 .\\n(2)Functions formerly exercisable by “the Ministers” (being, in relation to England and Wales and acting jointly, the Minister\\nof Agriculture, Fisheries and Food and the Secretaries of State respectively concerned with health in England and food and\\nhealth in Wales and, in relation to Scotland, the Secretary of State) are now exercisable in relation to England by the Secretary\\nof State pursuant to paragraphs 7 and 8 of Schedule 5 to the Food Standards Act 1999 (c. 28) , and paragraphs 12 and 21 of\\nthat Schedule amend sections 17(1) and 48 of the 1990 Act. Functions of “the Ministers” so far as exercisable in relation\\nto Wales were transferred to the National Assembly for Wales by the National Assembly for Wales (Transfer of Functions)\\nOrder 1999 (S.I. 1999/672 ), as read with section 40(3) of the 1999 Act, and those functions so far as exercisable in relation to\\nScotland were transferred to the Scottish Ministers by section 53 of the Scotland Act 1998 (c. 46)  as read with section 40(2)\\nof the 1999 Act. Regulation 13(4) of the Food Standards Act 1999 (Transitional and Consequential Provisions and Savings)\\n(England and Wales) Regulations 2000 (S.I. 2000/656 ) expressly authorises the Secretary of State to amend or revoke existing\\nRegulations made or having effect as if made by the Minister of Agriculture, Fisheries and Food (whether with others or not)\\nunder the 1990 Act.\\n(3)OJ No. L31, 1.2.2002, p.1.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_doc[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'BAAI/bge-base-en',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year',\n",
       "  'size_in_GB': 0.42,\n",
       "  'sources': {'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-base-en.tar.gz'},\n",
       "  'model_file': 'model_optimized.onnx'},\n",
       " {'model': 'BAAI/bge-base-en-v1.5',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year',\n",
       "  'size_in_GB': 0.21,\n",
       "  'sources': {'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-base-en-v1.5.tar.gz',\n",
       "   'hf': 'qdrant/bge-base-en-v1.5-onnx-q'},\n",
       "  'model_file': 'model_optimized.onnx'},\n",
       " {'model': 'BAAI/bge-large-en-v1.5',\n",
       "  'dim': 1024,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year',\n",
       "  'size_in_GB': 1.2,\n",
       "  'sources': {'hf': 'qdrant/bge-large-en-v1.5-onnx'},\n",
       "  'model_file': 'model.onnx'},\n",
       " {'model': 'BAAI/bge-small-en',\n",
       "  'dim': 384,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year',\n",
       "  'size_in_GB': 0.13,\n",
       "  'sources': {'url': 'https://storage.googleapis.com/qdrant-fastembed/BAAI-bge-small-en.tar.gz'},\n",
       "  'model_file': 'model_optimized.onnx'},\n",
       " {'model': 'BAAI/bge-small-en-v1.5',\n",
       "  'dim': 384,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year',\n",
       "  'size_in_GB': 0.067,\n",
       "  'sources': {'hf': 'qdrant/bge-small-en-v1.5-onnx-q'},\n",
       "  'model_file': 'model_optimized.onnx'},\n",
       " {'model': 'BAAI/bge-small-zh-v1.5',\n",
       "  'dim': 512,\n",
       "  'description': 'Text embeddings, Unimodal (text), Chinese, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year',\n",
       "  'size_in_GB': 0.09,\n",
       "  'sources': {'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-small-zh-v1.5.tar.gz'},\n",
       "  'model_file': 'model_optimized.onnx'},\n",
       " {'model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
       "  'dim': 384,\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~50 languages), 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2019 year',\n",
       "  'size_in_GB': 0.22,\n",
       "  'sources': {'hf': 'qdrant/paraphrase-multilingual-MiniLM-L12-v2-onnx-Q'},\n",
       "  'model_file': 'model_optimized.onnx'},\n",
       " {'model': 'thenlper/gte-large',\n",
       "  'dim': 1024,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year',\n",
       "  'size_in_GB': 1.2,\n",
       "  'sources': {'hf': 'qdrant/gte-large-onnx'},\n",
       "  'model_file': 'model.onnx'},\n",
       " {'model': 'mixedbread-ai/mxbai-embed-large-v1',\n",
       "  'dim': 1024,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 0.64,\n",
       "  'sources': {'hf': 'mixedbread-ai/mxbai-embed-large-v1'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-xs',\n",
       "  'dim': 384,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 0.09,\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-xs'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-s',\n",
       "  'dim': 384,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 0.13,\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-s'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-m',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 0.43,\n",
       "  'sources': {'hf': 'Snowflake/snowflake-arctic-embed-m'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-m-long',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 2048 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 0.54,\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-m-long'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-l',\n",
       "  'dim': 1024,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 1.02,\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-l'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'intfloat/multilingual-e5-large',\n",
       "  'dim': 1024,\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~100 languages), 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 2.24,\n",
       "  'sources': {'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-multilingual-e5-large.tar.gz',\n",
       "   'hf': 'qdrant/multilingual-e5-large-onnx'},\n",
       "  'model_file': 'model.onnx',\n",
       "  'additional_files': ['model.onnx_data']},\n",
       " {'model': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~50 languages), 384 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year',\n",
       "  'size_in_GB': 1.0,\n",
       "  'sources': {'hf': 'xenova/paraphrase-multilingual-mpnet-base-v2'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'Qdrant/clip-ViT-B-32-text',\n",
       "  'dim': 512,\n",
       "  'description': 'Text embeddings, Multimodal (text&image), English, 77 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year',\n",
       "  'size_in_GB': 0.25,\n",
       "  'sources': {'hf': 'Qdrant/clip-ViT-B-32-text'},\n",
       "  'model_file': 'model.onnx'},\n",
       " {'model': 'sentence-transformers/all-MiniLM-L6-v2',\n",
       "  'dim': 384,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 256 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year',\n",
       "  'size_in_GB': 0.09,\n",
       "  'sources': {'url': 'https://storage.googleapis.com/qdrant-fastembed/sentence-transformers-all-MiniLM-L6-v2.tar.gz',\n",
       "   'hf': 'qdrant/all-MiniLM-L6-v2-onnx'},\n",
       "  'model_file': 'model.onnx'},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-en',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year',\n",
       "  'size_in_GB': 0.52,\n",
       "  'sources': {'hf': 'xenova/jina-embeddings-v2-base-en'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'jinaai/jina-embeddings-v2-small-en',\n",
       "  'dim': 512,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year',\n",
       "  'size_in_GB': 0.12,\n",
       "  'sources': {'hf': 'xenova/jina-embeddings-v2-small-en'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-de',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (German, English), 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year',\n",
       "  'size_in_GB': 0.32,\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-de'},\n",
       "  'model_file': 'onnx/model_fp16.onnx'},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-code',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (English, 30 programming languages), 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year',\n",
       "  'size_in_GB': 0.64,\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-code'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'nomic-ai/nomic-embed-text-v1.5',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 0.52,\n",
       "  'sources': {'hf': 'nomic-ai/nomic-embed-text-v1.5'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'nomic-ai/nomic-embed-text-v1.5-Q',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 0.13,\n",
       "  'sources': {'hf': 'nomic-ai/nomic-embed-text-v1.5'},\n",
       "  'model_file': 'onnx/model_quantized.onnx'},\n",
       " {'model': 'nomic-ai/nomic-embed-text-v1',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 0.52,\n",
       "  'sources': {'hf': 'nomic-ai/nomic-embed-text-v1'},\n",
       "  'model_file': 'onnx/model.onnx'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastembed.embedding import TextEmbedding\n",
    "\n",
    "TextEmbedding.list_supported_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dense_embedding_model = FastEmbedEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "dense_embeddings = list(dense_embedding_model.embed_query(splitted_doc[0].page_content))\n",
    "len(dense_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 29 files: 100%|██████████| 29/29 [00:00<00:00, 28995.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastembed.sparse.bm25 import Bm25\n",
    "\n",
    "bm25_embedding_model = Bm25(\"Qdrant/bm25\")\n",
    "bm25_embeddings = list(bm25_embedding_model.passage_embed(splitted_doc[0].page_content))\n",
    "len(bm25_embeddings[0].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Late interaction embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed.late_interaction import LateInteractionTextEmbedding\n",
    "\n",
    "late_interaction_embedding_model = LateInteractionTextEmbedding(\"colbert-ir/colbertv2.0\")\n",
    "late_interaction_embeddings = list(late_interaction_embedding_model.passage_embed(splitted_doc[0].page_content))\n",
    "len(late_interaction_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
